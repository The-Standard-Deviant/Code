---
title: "Whatâ€™s in a Rating? Exploring What Factors Influence the Number of Yelp Food
  Reviews"
author: "Winston W. H. Eng"
header-includes:
  - \setlength\parindent{24pt}
  - \usepackage{fancyhdr}
  - \usepackage{lipsum}
  - \pagestyle{fancy}
  - \fancyfoot[CO,CE]{wie4}
  - \fancyfoot[LE,RO]{\thepage}
  - \fancypagestyle{plain}{\pagestyle{fancy}}
output:
  pdf_document:
    latex_engine: xelatex
    number_sections: yes
    toc: yes
  html_document:
    toc: yes
  word_document:
    toc: yes
  includes:
    in_header: latex/header.tex
    before_body: latex/before_body.tex
    after_body: latex/after_body.tex
bibliography: references.bib
---

```{r showcode, include=FALSE}
showCode <- F
```

```{r,echo=FALSE,message=FALSE,warning=FALSE}
require(knitr)
# Set so that long lines in R will be wrapped:
opts_chunk$set(tidy.opts=list(width.cutoff=80),tidy=TRUE)
```

```{r rpackages, include = FALSE}
library(dplyr)
library(ggplot2)
library(pander)
library(data.table)
library(leaflet)
library(stringr)
library(rms)
library(lars)
```


```{r loading datasets, include = FALSE}
setwd("/Users/wwheng/Documents/General/Academics/GSPH 2016-2017/Spring /BIOST 2049/Final Project/Data")
tip <- as.data.frame(fread("tip.csv"))

#946600 rows with 7 columns

setwd("/Users/wwheng/Documents/General/Yelp/Data/yelp_dataset_challenge_round9/")
business.yas <- jsonlite::stream_in(file("yelp_academic_dataset_business.json"))
#144072 records with 16 columns
```

```{r Pitt restaurants that are still open, echo = showCode}
#selecting Pitt only business
Pitt.bus <- business.yas[business.yas[, "city"] == "Pittsburgh", ]
#selecting only for food establishments
Pitt <- Pitt.bus[grepl("GoodForMeal", Pitt.bus$attributes),]
#only want a selection of variables
Pitt <- Pitt[, c("business_id", "name", "neighborhood", "postal_code", "stars", "review_count", "is_open")]
#only want those restaurants that are still open
Pitt <- Pitt[Pitt[, "is_open"] == "1", ]
```

```{r, business attributes, echo = showCode}
restaurants <- Pitt.bus[grepl("GoodForMeal", Pitt.bus$attributes),]
restaurants$bar <- NA
for(i in 1:nrow(restaurants)){
  
  if (grepl("Alcohol: full_bar", restaurants[i,"attributes"]) == TRUE){
  restaurants[i,"bar"] <- "Full Bar"
  }

  if (grepl("Alcohol: none", restaurants[i,"attributes"]) == TRUE){
  restaurants[i,"bar"] <- "None"
 }
  if (grepl("Alcohol: beer_and_wine", restaurants[i,"attributes"]) == TRUE){
  restaurants[i,"bar"] <- "Beer and Wine Only"
  }
}
restaurants$bar <- as.factor(restaurants$bar)


restaurants[,"Takeout"] <- NA
for(i in 1:nrow(restaurants)){
  if(grepl("RestaurantsTakeOut: True", restaurants[i,"attributes"]) == TRUE){
    restaurants[i, "Takeout"] <- "YES"
  } else if(grepl("RestaurantsTakeOut: False", restaurants[i,"attributes"]) == TRUE){
    restaurants[i, "Takeout"] <- "NO"
    
  }
}
restaurants$Takeout <- as.factor(restaurants$Takeout)


restaurants[,"Delivery"] <- NA
for(i in 1:nrow(restaurants)){
  if(grepl("RestaurantsDelivery: False", restaurants[i, "attributes"]) == TRUE){
    restaurants[i, "Delivery"] <- "NO"
  } else if(grepl("RestaurantsDelivery: True", restaurants[i, "attributes"]) == TRUE){
    restaurants[i, "Delivery"] <- "YES"
    }
}
restaurants$Delivery <- as.factor(restaurants$Delivery)

restaurants[,"Price"] <- NA
for(i in 1:nrow(restaurants)){
  if(grepl("RestaurantsPriceRange2: 1", restaurants[i, "attributes"]) == TRUE){
    restaurants[i, "Price"] <- "1"
  }
  if(grepl("RestaurantsPriceRange2: 2", restaurants[i, "attributes"]) == TRUE){
    restaurants[i, "Price"] <- "2"
  }
  if(grepl("RestaurantsPriceRange2: 3", restaurants[i, "attributes"]) == TRUE){
    restaurants[i, "Price"] <- "3"
  }
  if(grepl("RestaurantsPriceRange2: 4", restaurants[i, "attributes"]) == TRUE){
    restaurants[i, "Price"] <- "4"
  }
}
restaurants$Price <- as.factor(restaurants$Price)
#there were only four levels of price that could be found within the restaurants price attribute

#Restaurant Attire
restaurants[,"Attire"] <- NA
for(i in 1:nrow(restaurants)){
  if(grepl("RestaurantsAttire: dressy", restaurants[i, "attributes"]) == TRUE){
    restaurants[i, "Attire"] <- 'dressy'
  }
  else if(grepl("RestaurantsAttire: casual", restaurants[i, "attributes"]) == TRUE){
    restaurants[i, "Attire"] <- 'casual'
  }
}
restaurants$Attire <- as.factor(restaurants$Attire)


##Takes reservations
restaurants[,"Reservations"] <- NA
for(i in 1:nrow(restaurants)){
  if(grepl("RestaurantsReservations: False", restaurants[i, "attributes"]) == TRUE){
    restaurants[i, "Reservations"] <- 'NO'
  }
  else if(grepl("RestaurantsReservations: True", restaurants[i, "attributes"]) == TRUE){
    restaurants[i, "Reservations"] <- 'YES'
  }
}
restaurants$Reservations <- as.factor(restaurants$Reservations)


##noise level


##Good For... 
#GoodForMeal: {'dessert': False, 'latenight': False, 'lunch': True, 'dinner': False, 'breakfast': False, 'brunch': False}

### dessert
restaurants[,"GF.dessert"] <- NA
for(i in 1:nrow(restaurants)){
  if(grepl("'dessert': False", restaurants[i, "attributes"]) == TRUE){
    restaurants[i, "GF.dessert"] <- 'NO'
  }
  else if(grepl("'dessert': True", restaurants[i, "attributes"]) == TRUE){
    restaurants[i, "GF.dessert"] <- 'YES'
  }
}
restaurants$GF.dessert <- as.factor(restaurants$GF.dessert)

### latenight
restaurants[,"GF.latenight"] <- NA
for(i in 1:nrow(restaurants)){
  if(grepl("'latenight': False", restaurants[i, "attributes"]) == TRUE){
    restaurants[i, "GF.latenight"] <- 'NO'
  }
  else if(grepl("'latenight': True", restaurants[i, "attributes"]) == TRUE){
    restaurants[i, "GF.latenight"] <- 'YES'
  }
}
restaurants$GF.latenight <- as.factor(restaurants$GF.latenight)


### lunch
restaurants[,"GF.lunch"] <- NA
for(i in 1:nrow(restaurants)){
  if(grepl("'lunch': False", restaurants[i, "attributes"]) == TRUE){
    restaurants[i, "GF.lunch"] <- 'NO'
  }
  else if(grepl("'lunch': True", restaurants[i, "attributes"]) == TRUE){
    restaurants[i, "GF.lunch"] <- 'YES'
  }
}
restaurants$GF.lunch <- as.factor(restaurants$GF.lunch)


### dinner
restaurants[,"GF.dinner"] <- NA
for(i in 1:nrow(restaurants)){
  if(grepl("'dinner': False", restaurants[i, "attributes"]) == TRUE){
    restaurants[i, "GF.dinner"] <- 'NO'
  }
  else if(grepl("'dinner': True", restaurants[i, "attributes"]) == TRUE){
    restaurants[i, "GF.dinner"] <- 'YES'
  }
}
restaurants$GF.dinner <- as.factor(restaurants$GF.dinner)


### breakfast
restaurants[,"GF.breakfast"] <- NA
for(i in 1:nrow(restaurants)){
  if(grepl("'breakfast': False", restaurants[i, "attributes"]) == TRUE){
    restaurants[i, "GF.breakfast"] <- 'NO'
  }
  else if(grepl("'breakfast': True", restaurants[i, "attributes"]) == TRUE){
    restaurants[i, "GF.breakfast"] <- 'YES'
  }
}
restaurants$GF.breakfast <- as.factor(restaurants$GF.breakfast)

### brunch
restaurants[,"GF.brunch"] <- NA
for(i in 1:nrow(restaurants)){
  if(grepl("'brunch': False", restaurants[i, "attributes"]) == TRUE){
    restaurants[i, "GF.brunch"] <- 'NO'
  }
  else if(grepl("'brunch': True", restaurants[i, "attributes"]) == TRUE){
    restaurants[i, "GF.brunch"] <- 'YES'
  }
}
restaurants$GF.brunch <- as.factor(restaurants$GF.brunch)
```

```{r, echo=showCode}
or <- restaurants[restaurants[, "is_open"] == 1, ]
or <- subset(or, select = -c(address, city, state, is_open, attributes, categories, type))
or[or$neighborhood == "", "neighborhood"] <- NA
```

```{r # of tips, echo = showCode}
#subsetting tips to just include those from the the restaurants we are interested in
tip <- (tip[tip$business_id %in% or$business_id,])
#adding the number of tips for each business within the 'or' dataset
for(i in 1:nrow(or)){
  or[i, "tips"] <- length(grep(or[i,"business_id"], tip$business_id))
}

or$tips <- as.numeric(as.character(or$tips))
```

```{r final edits to dataset including removing NAs, echo = showCode}
or$stars <- as.factor(or$stars)
or$neighborhood <- as.factor(or$neighborhood)
or$review_count <- as.numeric(or$review_count)
or$postal_code <- as.factor(or$postal_code)
pitt.dat <- subset(or, select = -c(business_id, name,
                              postal_code, hours,
                              latitude, longitude,
                              neighborhood))
pitt.dat$log <- log(pitt.dat$review_count)
pitt.dat <- na.omit(pitt.dat)
```

\newpage

#ABSTRACT

## Objective
Yelp is a online service specializing in crowd-sourced reviews for local businesses. In an effort to spur "innovative research", the company has released data set samplings and subsequently encouraged students to dive deep. The objective of this evalution was focused on determining what factors influence the number of reviews a food business receives.

## Methods
1,168 Pittsburgh restaurants were selected from an international cohort. A number of user-submitted factors such as perceived price and quality of meal were collected alongside the restaurants' services such as availability for takeout and reservations. Simple linear regression was utilized to assess the relationship between these independent variables and the number of reviews a restaurant received. A final prediction model was created using information determined from a spearman $\rho$ rank squared test, and its validity was tested against automatic processes such as Stepwise Regression and LASSO.

## Results
Aside from one variable, each of the predictors, individually, had a statistically significant ability to predict the number of reviews a restaurant would receive; related $r^{2}$ values ranged from 0.02 to 0.15 with one variable having as high a value as 0.516. In contrast, the final prediction model (dubbed the "Spearman Regression Model") had the highest $r^{2}$ (0.801) and lowest MSE (0.267), AIC (1832), and BIC (1984) values. The "Stepwise Regression" and "LASSO" techniques performed no better than the "Spearman Approach"" in all four of those categories.

## Conclusion
Not all of the predictors exhibited monotonic relationships with the outcome variable. The "Spearman Approach" was created as a consequence of putting this theory into practice and manually choosing where to spend the degrees of freedom. The resulting model produced the most accurate results and subsequently provided greater insights into which predictors best influence the number of reviews a food business would receive.

\newpage
#INTRODUCTION

Electronic word-of-mouth (eWOM) can be defined by "any positive or negative statement made by potential, actual, or former customers about a product or company, which is made available to a multitude of people and institutions via the Internet." [@hennig2004electronic] It has often been credited as having an incredibly amount of influence in our current culture; customers have been cited as seeing online reviews as "more trustworthy and persuasive than traditional media, such as print ads, personal selling, and radio and TV advertising" and "more influential in their decision than speaking with friends in person". [@cheung2012impact, @steffes2009social] It should be no surprise that engaging in such online communication spectrums could be seen as extremely beneficial in helping to assess the wellbeing of a current business or product.

Since 2004, the world has had Yelp, a website and mobile app designed around the concept of rating business, culinary and otherwise, in a numerical and descriptive manner. With 24 and 73 million unique users on mobile and desktop respectively, the company fits into the category of "Web 2.0 sites" where user-submitted reviews are targeted at a primary audience of other consumers. [@Yelp2016, @tucker2011online] In the words of Stephanie Ichinos, ex-Senior Director of Communications, these reviews "supply information to the bloggers, support local businesses, [and] help share potentially useful information with others..." These criticisms are heavily integrated into the livelihood of these establishments; even an "one-star increase in Yelp rating" has been shown to "lead to over a 5-9 percent increase in revenue". [@luca2016reviews]

In an effort to contribute to the literature surrounding the influence of eWOM on local food establishments, this study seeks to determine what combination of restaurant factors impact the number of reviews it will receive. From an initial assessment of over 4.1 million reviews and 947,000 tips by 1 million users for 144,000 business provided by the Yelp in the 9th round of the Yelp Dataset Challenge, an objective was developed to create a prediction model capable of relating the relationships amongst these variables most accurately. Given the complexity and difficulty assumed in relating qualitative experiences with quantitative measures, the author hypothesizes that there might exist non-monotonic relationships within the data which may influence the considerations taken during model generation.



\newpage
#METHODOLOGY

##Sample Selection
The Yelp Dataset included 144,072 businesses spanning 11 international locations. Businesses not within the food industry were excluded. Additionally, restaurants that were missing data on any of the variables were excluded. In total, the final sample size consisted of 1,168 currently open restaurants within the city of Pittsburgh.

## Data Dictionary
```{r variables and their definitions, echo = showCode}
varz <- (subset(pitt.dat, select = -c(log)))
Variable.Name  <- colnames(varz[,c("stars", "bar", "Takeout", "Delivery", "Reservations", "GF.breakfast", "GF.brunch",
                   'GF.lunch', "GF.dinner", "GF.dessert", "GF.latenight", "tips", "review_count")])

Description <- c("Number of Stars a Restaurant Received",
                 "Type of Alcohol Service Available",
                 "Availability of Takeout",
                 "Availability of Delivery",
                 "Availability to set a Reservation",
                 "Considered 'Good For Breakfast'",
                 "Considered 'Good For Brunch'",
                 "Considered 'Good For Lunch'",
                 "Considered 'Good For Dinner'",
                 "Considered 'Good For Dessert'",
                 "Considered 'Good For Late Night'",
                 "Total Number of Tips a Restaurant Received",
                 "The Number of Reviews a Restaurant Received"
                 )
Variable.Type <- c(rep("Predictor", 12), "Outcome")
dat.dic <- data.frame(Variable.Name, Description, Variable.Type)
dat.dic <- dat.dic %>% 
  mutate(Variable.Name = Variable.Name)

pander(dat.dic, caption = "Data Dictionary of Regression Model Variables")
```

For ease and consistency, the variables will be **bolded** and referenced using the names within the data dictionary. Parenthesized superscripts will act as references to graphics within the Appendix section of the paper.

##Transformation of Outcome Variable
The outcome variable **review_count** did not follow a normal distribution \textsuperscript{(6.1)}. After applying a log transformation to the data, it appeared more normally distributed \textsuperscript{(6.2)}, so this form of **review_count** was used in the analyses. These assessments took the form of kernel density plots.


##Statistical Analysis
```{r spearman for non-monotonic relationship, include = showCode}
jack <- with(pitt.dat, spearman2(log ~ 
              stars        + 
              bar          + 
              Takeout      + 
              Delivery     + 
              Price        + 
              Attire       + 
              Reservations +
              GF.brunch    +
              GF.breakfast +
              GF.latenight +
              GF.dinner    + 
              tips))
```

\indent Descriptive statistics included assessment of the number, mean, and standard deviation of the different categorical variables. Additionally, Violin plots provided a visual assessment of the distribution of **review_count** per each variable; kernel density estimates were mirrored and formed a symmetrical shape. Red points indicated outliers or values outside 1.5 times the interquartile range, while white points demonstrated the median value; the black boxes acted as boxplots. To test linear relationships, scatterplots were used, and collinearity was evaluated via variance inflation factor calculations.\par

\indent Initially, a simple linear regression was used to determine how well each independent variable would be able to predict **review_count**; if the f-statistic had a related p-value less than a critical p-value of 0.05, the predictor was considered to have a statistically significant relationship with the outcome. While interactions were considered amongst all of the different variables, it was worth noting that to aid with interpreting and maintaining a more parsimonious model, each possible iteration was not considered. \par

\indent Subsequently, two different model approaches were used: 1) Manual vs 2) Automatic. As the objective was created with the former process in mind, the automatic techniques offered an opportunity to test the manual model's validity. \par

\indent An assumption used was that each of the independent variables had a monotonic relationship with the outcome variable. However, if this were to be false, the ability for a model to accurately assess the outcome variable could be called into question. Therefore, in order to confirm the potential existence of non-monotonic relationships, evaluation of the square of a quadratic rank generalized of Spearman's $\rho$ coefficient was necessary. \par

For the first category, a Spearman's $\rho^{2}$ was initially ran to determine if all relationships between each of the independent variables with the outcome were monotonic. In general, the spearman $\rho^{2}$ will "detect not only nonlinear relationships (as will ordinary Spearman $\rho$) but some non-monotonic ones as well." [@harrell2015regression]\par

It has been suggested that there shouldn't be more than 15 observations per predictors [@harrell2015regression]; while, others suggests a maximum of 10 observations per predictor. [@vittinghoff2011regression] Since there were `r nrow(pitt.dat)` observations, the max amount of predictors that could theoretically be kept within the model would be `r floor(nrow(pitt.dat)/15)`. As there were already `r nrow(jack)` variables within the equation, it was deemed acceptable to allow for transformations of the variables without violating these regression guidelines.

```{r spearman plots, echo = showCode}
plot(jack)
```

Based on the Spearman Plot, it appeared that the three most likely to have a non-monotonic relationship with the outcome variable were **tips**, **GF.dinner**, and **Price**.


The **tips** variable had a quartic spline applied to it as well as interactions set between itself and **GF.dinner** and **Price** respectively. Justification is that, by convention, a greater number of tips should indicate an overall greater "perception" of the restaurant; this should hold especially for dinner where special occasions are generally more common. Whether positively or negatively, if a restaurant had enough of an impact on an individual as to have that person leave a tip, it is very possible to expect that same customer to leave a review as well. Furthermore, restaurants that typically stand out to people are those that could be described as "worthwhile experiences". For a college student, this may mean a filling, delicious, and cheap meal, while for a person looking for a fancy dinner, it may mean splurging on a place with a reputation to be upscale. Demographics of Yelp aside, it should be possible to imagine that **tips** and **price** could have a meaningful interaction in such a manner. Subsequently, after this spearman $\rho$ assessment, an ordinary least squares (OLS) regression model was then created from these selected variables.\par

\indent For the second category, bi-directional stepwise regression and Least Absolute Shrinkage and Selection Operator (LASSO) models were run. The stepwise approach utilized an AIC criteria that dropped or added variables based on **$-2 \times (log likelihood) + 2p$** where `p` was the rank of the model, while the LASSO relied on the least angle regression algorithm developed by Tibshirani, *et al*. [@tibshirani1996regression] \par

\indent Following the creation of the models, all of the comparative outputs were summarized in Table 2. Furthermore, studentized residuals were calculated and plotted against the fitted values, while histograms were created to determine their overall normality. Leverage and Cook's Distance plots were created to determine outliers and influential points; if points were deemed statistically significantly influential, the models were assessed with and without those points' inclusion. All analysis and discussion was created using RStudio's `RMarkdown` and `R Version 1.0.136`.




```{r spearman model, include = showCode}
spear <- lm(log ~ 
              rcs(tips, 4) +
              stars        + #0 missing
              bar          + #88 missing
              Takeout      +  #14 missing
              Delivery     + #36 missing
              Attire       + #51 missing
              Reservations +
              GF.brunch    +
              GF.breakfast +
              GF.latenight +
              GF.dinner    +
              Price        +
              GF.dinner %ia% tips +
              Price %ia% tips
              , data = pitt.dat)
```

```{r lasso model, include = showCode}
preds <-  with(pitt.dat, cbind(stars, bar, Takeout, Delivery,
                          Price, Attire, GF.brunch, GF.breakfast,
                          Reservations,
                          GF.latenight, GF.dinner, tips))

lasso1 <- lars(preds, pitt.dat$log, type = "lasso")
plot(lasso1)
lassocv <- cv.lars(preds, pitt.dat$log, K = 10)
frac <- lassocv$index[which.min(lassocv$cv)]
coef.cv <- coef(lasso1, s= frac, mode = "fraction")
round(coef.cv, 4)
#lasso is most useful when we believe that not all of the predictors are having a HUGE effect
#basically we should retain all of this
```

```{r linear regression and stepwise, include = showCode}
yas <- with(pitt.dat, lm(log ~ 
              stars        + #0 missing
              bar          + #88 missing
              Takeout      +  #14 missing
              Delivery     + #36 missing
              Price        + #9 missing
              Attire       + #51 missing
              Reservations +
              GF.brunch    +
              GF.breakfast +
              GF.latenight +
              GF.dinner    + 
              tips))

nah <- step(yas)
```


```{r Model variables, echo = showCode}
first <- c("Spearman Approach", "Stepwise Approach", "LASSO Approach")
s3 <- paste("log ~ stars + bar + Takeout + Delivery + Price + Attire + Reservations + GF.brunch + GF.breakfast + GF.latenight + GF.dinner + tips")
s2 <- paste("log ~ stars + bar + Price + Attire + Reservations + GF.brunch + GF.breakfast + GF.latenight + GF.dinner + tips")
s1 <- paste("log ~ rcs(tips, 4) + stars + bar + Takeout + Delivery + Attire + Reservations + GF.brunch + GF.breakfast + GF.latenight +  GF.dinner + Price + GF.dinner %ia% tips + Price %ia% tips")
second <- append(append(s1, s2), s3)
Notes <- c("'rcs(x, 4)' = quartic spline on the variable 'x', 'y %ia% z' = interaction between variable y and z", "NA", "the same as the full model")
explain <- data.frame(first, second, Notes)
explain <- rename(explain, Model = first)
explain <- rename(explain, Formula = second)
explain <- explain %>%
  mutate(Model = Model)
```
\newpage

#RESULTS

## Descriptive Statistics

When looking at the descriptive statistics of each of the different variables, it is worth noting that the distribution of **review_count** is not equal amongst all of the different levels within the 13 independent variables. For instance as demonstrated in Reference 6.3, the distribution of **stars** is not equal; 12 restaurants had a 1.5 star rating, while 353 had 4 stars.\textsuperscript{(6.3)} This is also physically evident in the subsequent graphic comprising of violin plots.\textsuperscript{(6.4)} It is worth noting that most of the variables used were categorical and had between 2 to 3 levels. When looking at the scatterplots of each independent variable against the **review_count**, most appeared linear; however, the scatterplot for **review_count** vs **stars** appeared to be curved.\textsuperscript{(6.5)}

## Comparing Regression Models
```{r comparing, echo = showCode}
heck <- subset(pitt.dat, select = -c(review_count))
  a <- vector()
  b <- vector()
  c <- vector()
  d <- vector()
  e <- vector()
  f <- vector()
for (i in 1:14) {
  jill <- heck[,i]
  lin <- lm(log ~ jill, data = heck)
  a <- append(a, round(summary(lin)$r.squared, 3))
  b <- append(b, round(mean(lin$residuals ^ 2), 3))
  c <- append(c, round(anova(lin)[, "F value"][1],3))
  d <- append(d, round(anova(lin)[, "Pr(>F)"][1], 3))
  e <- append(e, round(AIC(lin), 3))
  f <- append(f, round(BIC(lin), 3))
}
Model <- colnames(subset(heck, select = -c(log)))  

a <- append(a, round(summary(spear)$r.squared, 3))
b <- append(b, round(mean(spear$residuals ^ 2), 3))
c <- append(c, round(summary(spear)$fstatistic[1], 3))
d <- append(d, round(anova(spear)[,"Pr(>F)"][1], 3))
e <- append(e, round(AIC(spear), 3))
f <- append(f, round(BIC(spear), 3))

Model <- append(Model, "Spearman Approach")

a <- append(a, round(summary(nah)$r.squared, 3))
b <- append(b, round(mean(nah$residuals ^ 2), 3))
c <- append(c, round(summary(nah)$fstatistic[1], 3))
d <- append(d, round(anova(nah)[,"Pr(>F)"][1], 3))
e <- append(e, round(AIC(nah), 3))
f <- append(f, round(BIC(nah), 3))

Model <- append(Model, "Stepwise Approach")

a <- append(a, round(summary(yas)$r.squared, 3))
b <- append(b, round(mean(yas$residuals ^ 2), 3))
c <- append(c, round(summary(yas)$fstatistic[1], 3))
d <- append(d, round(anova(yas)[,"Pr(>F)"][1], 3))
e <- append(e, round(AIC(yas), 3))
f <- append(f, round(BIC(yas), 3))

Model <- append(Model, "LASSO Approach")


mod.tot <- data.frame(Model, a, b, c, d, e, f)

mod.tot <- rename(mod.tot, R.Squared = a)
mod.tot <- rename(mod.tot, MSE = b)
mod.tot <- rename(mod.tot, "F.Statistic" = c)
mod.tot <- rename(mod.tot, "P-Value" = d)
mod.tot <- rename(mod.tot, AIC = e)
mod.tot <- rename(mod.tot, BIC = f)

mod.tot$`P-Value` <- as.character(mod.tot$`P-Value`)
for(i in 1:nrow(mod.tot)){
  if (mod.tot[i,"P-Value"] == "0"){
    mod.tot[i,"P-Value"] <- "< 2.2e-16"
  }
}
mod.tot <- mod.tot %>%
  mutate(R.Squared = R.Squared * 1)
pander(mod.tot, caption = "Regression Models and their Outputs")
```

## Simple Linear Regression Models

For the simple linear regression models, each independent variable, aside from **GF.breakfast**, was statistically significantly able to predict the **review_count** against a critical p-value of 0.05. For the most part, the amount of variation for which each variable was able to account was between 2-15%. An anomaly, the **tips** variable demonstrated the highest $r^{2}$ value of 0.516. The related q-q plots showed no deviations from normality; this was also true for the **GF.breakfast** model. However, the studentized vs fitted residuals graphs did generally have fanning.\textsuperscript{(6.6)}

## Spearman Regression Model

After creating the Spearman $\rho$ Rank Square Plot and selecting to spend degrees of freedom on the **price**, **GF.dinner**, and **tips** variables, the model included the following variables:

```{r Spearman formula, echo = showCode}
pander(explain[1, ], caption = "Formula of Spearman Regression Model with Notes")
```

A quartic spline was applied to the **tips** variable, while interactions took place between **tips** and **GF.dinner** and **Price** respectively.

With a F-statistic of 163.8 and a p-value < 0.001, the spearman model was able to account for over 80.1% of the variation; it had the lowest MSE, AIC, and BIC values of 0.267, 1832, and 1984 respectively. When assessing the variance inflation factor (VIF) of the variables, there were some that had values greater than the a critical value of 5.0. However, these outliers tended to fall within two categories, either 1) they were indicator variables representing categories with 3 or more levels or 2) they were interactions between different variables. Having high VIFs within categorical dummy variables should not be considered problematic as often "nothing else in the regression is affected." [@allison2012multicollinearity] Additionally, higher VIF values are expected when including power transformations or interactions of other variables; by their very natures, there should exist influential underlying relationships. \par

When plotting the residuals vs fitted, there was a very slight funneling in the residuals vs fitted plot, possibly demonstrating some non-linear pattern within the residuals. \textsuperscript{(6.7)} However, in the scale-location plot, the residuals appeared equally spread out, indicating no homoscedasticity violation. Additionally, the Q-Q plot appeared to be normal, and there did not appear to be any points with high influence or leverage.\par

## Stepwise Regression Model
Recall that the stepwise regression approach is helpful when trying to determine, from a handful of variables, which best combination can lead to the lowest AIC or lowest amount of information loss. 

```{r stepwise formula, echo = showCode}
pander(explain[2, ], caption = "Formula of Stepwise Regression Model with Notes")
```

With a F-statistic of 121.6 and a p-value < 0.001, the spearman model was able to account for over 67.9% of the variation; its MSE, AIC, and BIC values were 0.43, 2374, and 2485 respectively. Unlike the spearman regression, this model did not retain the **Takeout** or **Delivery** variables. However, it's VIF levels mirrored similar hightened results for the same variables as the spearman regression had produced. When plotting the residual versus fitted, there was an intense clustering and funneling of the data.

## LASSO Regression Model
In theory, the LASSO approach is most useful when it is believed that not all of the predictors are having an incredibly impactful effect on predicting the outcome. When running the model, none of the coefficients, after cross-validation, were dropped. Hence, via the LASSO approach, it is suggested that all of the different variables should be retained within the prediction model. Compared to the Spearman Regression, LASSO lacked the interacions and quartic spline.

```{r LASSO formula, echo = showCode}
pander(explain[3, ], caption = "Formula of LASSO Regression Model with Notes")
```


With a F-statistic of 110.7 and a p-value < 0.001, the LASSO model was able to account for over 68% of the variation; its MSE, AIC, and BIC values were 0.429, 2375, and 2496 respectively. It's VIF and residuals vs fitted plot mirrored that of the stepwise regression model.
\newpage

#DISCUSSION

The main focus of this study was to determine which best combination of factors was most capable of accurately determining the number of reviews a restaurant would receive. In this case, I found that the spearman regression approach produced the most accurate model when compared to the stepwise and LASSO techniques. While, the model could only account for 80.1% of the variation, it outperformed all other approaches, demonstrating that non-monotonic relationships should be included and assessed when dealing with this type of data.\par

With regards to the regression coefficients, each of them were statistically significant against a critical p-value of 0.05 except for 1) the indicator variable regardng whether a restaurant was "good for breakfast" (p = 0.121) and 2) the interaction between the perceived price of a restaurant and the number of tips it received (p = 0.464367). \par

With regards to the **GF.Breakfast** variable, this type of non-statistical significant contradicts what may be found within the stepwise and LASSO models; the same variable had critical p-values < 0.001 in their results. This type of statistically significant reversal happened for the **Takeout** variable as well. While the stepwise model dropped **Takeout** and the LASSO model deemed it non-significant, the Spearman Regression model's version had treated it as statistically signficant with a p-value of 0.00335. \par

Surprisingly, this appears to coincide with previous research which rated "takeout" as the second most cared about aspect of a restaurant based on Yelp reviews. [@huang2014improving] Additionally, Huang *et al.* found that "breakfast" was rated on the lower end of importance, being a part of only 0.59% of all reviews. \par

Limitations to this analysis sources heavily from the failure to include additional data types provided within the Yelp Dataset Challenge. While the author did account for the number of reviews a specific restaurant received, there was not a deeper dive into the specific words used within the reviews themselves; perhaps, appling a variation of natural language processing could have given greater insights into the quality of reviews and how that would influence the type of reviews a restaurant would receive. Moreover, visual pieces such as pictures of food, restaurants themselves, and even the patrons/reviewers were not evaluated. Peak times and the cyclic nature of businesses during the workshift were not included; as previous analyses have cited "service"" and "decor" as most important "hidden topics" for reviewers when looking at a restaurant, future work should consider including these types of variables into the model. [@huang2014improving] \par

It is clear that there are environmental factors that were not considered in this specific analysis. However, given the assumptions that were made within this paper, there doesn't appear to be an irregular deviation from what has been generally discussed in the literature.


\newpage




#Appendix
```{r functions, echo = showCode}
tabs <- function(foo, ...) foo %>%
  group_by_(...) %>%
  summarise(N = length(log),
            Mean = round(mean(log), 3),
            Standard.Deviation = round(sd(log), 3))

bins <- function(foo){
  ggplot(pitt.dat, aes(x = foo)) +
    geom_histogram(aes(y = ..density..)) +
    stat_function(fun = dnorm,
                  args = list(mean = mean(foo),
                              sd = sd(foo)),
                  col = 'red')
}

vio <- function(foo){
  ggplot(pitt.dat, aes(x = foo, y = log)) +
    geom_violin() + 
    #theme_bw() +
    geom_boxplot(width = 0.1, fill = "black",
                 outlier.color = "red",
                 outlier.size = 2.5) +
    stat_summary(fun.y = median, geom = "point",
                 fill = "white", shape = 21, size = 2.5) +
    ylab("Review Count (Log-Transformed)")
}

scatter <- function(foo){
  ggplot(pitt.dat, aes(foo, log)) + 
    geom_point(aes(colour = factor(foo))) +
    labs(colour = "Levels") +
    ylab("Review Count (Log-Transformed)")
}
```

## Kernel Density Distribution of Review Count

```{r Density with Review , echo = showCode, message = FALSE}
bins(pitt.dat$review_count) +
  ggtitle("Kernel Density of Review Counts with Related Curve") +
  xlab("Number of Reviews") +
  ylab("Kernel Density")
```

## Kernel Density Distribution of Log-Transformed Review Count
```{r Density with Log(Review), echo = showCode, message = FALSE}
bins(pitt.dat$log) + 
  ggtitle("Kernel Density of Log-Transformed Review Counts with Related Curve") +
  xlab("Review Count (Log-Transformed)") +
  ylab("Kernel Density")

```

## Summary Statistics of Stars Count (N, Mean, Standard Deviation)
```{r Summary statistics, echo = showCode}
pander(tabs(pitt.dat, "stars"), caption = "Distribution of Stars Assigned to Restaurants")
```

## Kernel Density Distribution of Stars Count via Violin Plots

```{r violinplots, echo = showCode}
vio(pitt.dat$stars) +
  ggtitle("Kernel Density Distribution of Reviews by 'Star' Count") +
  xlab("Star Count")
```

## Scatterplot of Review Count vs Stars Count

```{r scatterplots, echo = showCode}
scatter(pitt.dat$stars) +
  xlab("Star Count") +
  ggtitle("Scatterplot of Review Count vs Stars Count Restaurants Received")
```

## Studentized Residuals vs Fitted Plot for Stars Count Linear Regression
```{r Residuals vs fitted, echo =showCode}
winston <- lm(log ~ stars, data = pitt.dat)
plot(winston, which = 1, sub = "'Review Count vs Stars Count'")
```

## Studentized Residuals Vs Fitted Plot for Spearman Regression Model
```{r, echo = showCode}
plot(spear, which = 1, sub.caption = "")
```

\newpage


#References

